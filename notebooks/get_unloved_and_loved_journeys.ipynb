{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T13:36:59.291030Z",
     "start_time": "2019-03-05T13:36:57.034500Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm.pandas(tqdm_notebook)\n",
    "from datetime import datetime\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.getenv(\"DATA_DIR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Page-level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data (content items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T13:37:00.589091Z",
     "start_time": "2019-03-05T13:36:59.294452Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_content_df = pd.read_csv(os.path.join(DATA_DIR, 'metadata/clean_content_links.csv')\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep only pages with related links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T13:38:30.577892Z",
     "start_time": "2019-03-05T13:38:30.489351Z"
    }
   },
   "outputs": [],
   "source": [
    "# only select rows that have related links (they have \n",
    "# related_mainstream_content, ordered_related_items, or quick_links)\n",
    "clean_content_rl_df = clean_content_df.copy().query(\n",
    "    'related_mainstream_content.notnull() or ordered_related_items.notnull()or part_of_step_navs.notnull() or quick_links.notnull()'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_path</th>\n",
       "      <th>content_id</th>\n",
       "      <th>document_type</th>\n",
       "      <th>primary_publishing_organisation</th>\n",
       "      <th>publishing_app</th>\n",
       "      <th>title</th>\n",
       "      <th>ordered_related_items</th>\n",
       "      <th>quick_links</th>\n",
       "      <th>related_mainstream_content</th>\n",
       "      <th>related_guides</th>\n",
       "      <th>document_collections</th>\n",
       "      <th>part_of_step_navs</th>\n",
       "      <th>related_to_step_navs</th>\n",
       "      <th>slugs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176880</th>\n",
       "      <td>/hunting</td>\n",
       "      <td>8642926f-6bec-40c7-a158-e5e9c5361254</td>\n",
       "      <td>guide</td>\n",
       "      <td>Government Digital Service</td>\n",
       "      <td>publisher</td>\n",
       "      <td>hunting and shooting wildlife</td>\n",
       "      <td>['9d06120f-4f08-407c-b98e-b849a48cf9a0', 'e516...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['overview', 'Birds', 'mammals']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       base_path                            content_id document_type  \\\n",
       "176880  /hunting  8642926f-6bec-40c7-a158-e5e9c5361254         guide   \n",
       "\n",
       "       primary_publishing_organisation publishing_app  \\\n",
       "176880      Government Digital Service      publisher   \n",
       "\n",
       "                                title  \\\n",
       "176880  hunting and shooting wildlife   \n",
       "\n",
       "                                    ordered_related_items  quick_links  \\\n",
       "176880  ['9d06120f-4f08-407c-b98e-b849a48cf9a0', 'e516...          NaN   \n",
       "\n",
       "       related_mainstream_content related_guides document_collections  \\\n",
       "176880                        NaN            NaN                  NaN   \n",
       "\n",
       "       part_of_step_navs related_to_step_navs  \\\n",
       "176880               NaN                  NaN   \n",
       "\n",
       "                                   slugs  \n",
       "176880  ['overview', 'Birds', 'mammals']  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_content_rl_df[clean_content_rl_df['base_path']=='/hunting']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidy related link pages data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T13:38:31.515900Z",
     "start_time": "2019-03-05T13:38:31.464231Z"
    }
   },
   "outputs": [],
   "source": [
    "# fill NaNs with empty arrays, and then literal_eval all the arrays so we can\n",
    "# access the items within them (the different slugs associated with each\n",
    "# content ID)\n",
    "clean_content_rl_df['slugs'] = clean_content_rl_df['slugs'].fillna(\"['']\").apply(\n",
    "    ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This converts the string to a list and puts an empty list where there are none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T13:38:32.667663Z",
     "start_time": "2019-03-05T13:38:32.664524Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_content_rl_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T13:38:33.667398Z",
     "start_time": "2019-03-05T13:38:33.664200Z"
    }
   },
   "outputs": [],
   "source": [
    "# sometimes there isn't an empty slug in the list of slugs, but the page path\n",
    "# exists, so this is a little hack to includ the plain basePath\n",
    "def add_dummy_slug(slugs):\n",
    "    list1 = ['']\n",
    "    list1.extend(slugs)\n",
    "    return list(set(list1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dummmy_slug is the url without any slug which  is also a page so needs an empty slug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T13:38:37.345026Z",
     "start_time": "2019-03-05T13:38:37.338481Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_content_rl_df['slugs'] = clean_content_rl_df['slugs'].apply(add_dummy_slug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wide to long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T13:38:39.194625Z",
     "start_time": "2019-03-05T13:38:39.189133Z"
    }
   },
   "outputs": [],
   "source": [
    "# adapted from https://gist.github.com/jlln/338b4b0b55bd6984f883\n",
    "def splitDataFrameList(df,target_column):\n",
    "    '''\n",
    "    df = dataframe to split,\n",
    "    target_column = the column containing the values to split, in an array\n",
    "    returns: a dataframe with each entry for the target column separated,\n",
    "        with each element moved into a new row. The values in the other\n",
    "        columns are duplicated across the newly divided rows.\n",
    "    '''\n",
    "    def splitListToRows(row,row_accumulator,target_column):\n",
    "        for s in row[target_column]:\n",
    "            new_row = row.to_dict()\n",
    "            new_row[target_column] = s\n",
    "            row_accumulator.append(new_row)\n",
    "    new_rows = []\n",
    "    df.apply(splitListToRows,axis=1,args = (new_rows,target_column))\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T13:38:42.779207Z",
     "start_time": "2019-03-05T13:38:42.515622Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_content_exploded_df = splitDataFrameList(\n",
    "    clean_content_rl_df, 'slugs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T16:13:13.897719Z",
     "start_time": "2019-03-04T16:13:13.894423Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_slash_between_basepath_slug(slug):\n",
    "    if slug == '':\n",
    "        return ''\n",
    "    else:\n",
    "        return '/' + slug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T16:13:14.450255Z",
     "start_time": "2019-03-04T16:13:14.444566Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_content_exploded_df['slug'] = clean_content_exploded_df['slugs'].map(\n",
    "    add_slash_between_basepath_slug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T16:13:15.103071Z",
     "start_time": "2019-03-04T16:13:15.094796Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_content_exploded_df['pagePath'] = clean_content_exploded_df['base_path']  + clean_content_exploded_df['slug']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T16:48:37.100274Z",
     "start_time": "2019-03-04T16:48:36.969169Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_content_exploded_df.to_csv(os.path.join(DATA_DIR, 'metadata/loved_pages.csv.gz'),\n",
    "                        compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMART answers needed separately as each answer gets a new slug so the beginning of the url is matched to classify these as loved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T11:35:25.388279Z",
     "start_time": "2019-03-05T11:35:25.364954Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_content_exploded_df[\n",
    "    clean_content_exploded_df['document_type'] == 'simple_smart_answer'].to_csv(os.path.join(DATA_DIR, 'metadata/loved_smart_answers.csv.gz'),\n",
    "                        compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Journey-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T09:37:14.577565Z",
     "start_time": "2019-03-05T09:37:14.574794Z"
    }
   },
   "outputs": [],
   "source": [
    "REQUIRED_COLUMNS = [\"Occurrences\", \"ABVariant\", \"Page_Event_List\",\n",
    "                    \"Page_List\",  \"Event_cat_act_agg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T09:33:21.459888Z",
     "start_time": "2019-03-05T09:33:21.424965Z"
    }
   },
   "outputs": [],
   "source": [
    "loved_pages_df = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, 'metadata/loved_pages.csv.gz'),\n",
    "    usecols=['pagePath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T09:37:13.456100Z",
     "start_time": "2019-03-05T09:37:13.449377Z"
    }
   },
   "outputs": [],
   "source": [
    "# dedupe the pagePaths here just in case\n",
    "loved_page_paths = list(set(loved_pages_df['pagePath'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T09:38:25.757449Z",
     "start_time": "2019-03-05T09:38:25.754148Z"
    }
   },
   "outputs": [],
   "source": [
    "loved_page_paths_set = set(loved_page_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T11:37:51.500048Z",
     "start_time": "2019-03-05T11:37:51.467158Z"
    }
   },
   "outputs": [],
   "source": [
    "loved_smart_answers_df = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, 'metadata/loved_smart_answers.csv.gz'),\n",
    "    usecols=['pagePath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T11:41:14.696234Z",
     "start_time": "2019-03-05T11:41:14.675511Z"
    }
   },
   "outputs": [],
   "source": [
    "loved_smart_answers_df['pagePath'] = loved_smart_answers_df['pagePath'] + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T11:41:15.454159Z",
     "start_time": "2019-03-05T11:41:15.450864Z"
    }
   },
   "outputs": [],
   "source": [
    "loved_smart_answers = list(set(\n",
    "    loved_smart_answers_df['pagePath'].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the pages come from links in this page https://www.gov.uk/government/organisations/hm-revenue-customs/contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T12:09:53.997886Z",
     "start_time": "2019-03-05T12:09:53.981379Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, 'metadata/hmrc_contact_pages.json'), \"r\") as read_file:\n",
    "    contact_pages = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T12:12:13.740610Z",
     "start_time": "2019-03-05T12:12:13.737380Z"
    }
   },
   "outputs": [],
   "source": [
    "hmrc_contact_pages = [link['base_path'] for link in contact_pages['links']['children']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T12:12:22.494437Z",
     "start_time": "2019-03-05T12:12:22.489137Z"
    }
   },
   "outputs": [],
   "source": [
    "hmrc_contact_pages_set = set(hmrc_contact_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T12:12:38.145108Z",
     "start_time": "2019-03-05T12:12:38.140612Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_loved_page(page):\n",
    "    return any([\n",
    "        re.match('/foreign-travel-advice/',page),\n",
    "        page in hmrc_contact_pages_set,\n",
    "        page in loved_page_paths_set,\n",
    "        page == '/help',\n",
    "        re.match('/premises-licence/',page),\n",
    "        page in ['/help/terms-conditions', \n",
    "         '/help/about-govuk',\n",
    "         '/help/accessibility', \n",
    "         '/help/privacy-policy',\n",
    "         '/help/cookies', \n",
    "         '/help/update-email-notifications',\n",
    "         '/help/browsers', \n",
    "         '/help/beta'],\n",
    "        re.match('/find-local-council/',page),\n",
    "        any([pagepath in page for pagepath in loved_smart_answers]), \n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T12:18:11.670357Z",
     "start_time": "2019-03-05T12:18:11.664297Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_daily_data(file_prefix):\n",
    "    print(f\"reading {file_prefix} data\")\n",
    "    df = pd.read_csv(\n",
    "        os.path.join(DATA_DIR, f'processed_journey/taxon_ab_{file_prefix}.csv.gz'), \n",
    "        sep='\\t', \n",
    "        usecols=REQUIRED_COLUMNS)\n",
    "    print(\"page_list to literal list\")\n",
    "    df['Page_List'] = df['Page_List'].apply(ast.literal_eval)\n",
    "    print(\"page_event_list to literal list\")\n",
    "    df['Page_Event_List'] = df['Page_Event_List'].apply(ast.literal_eval)\n",
    "    print(\"Derive var: there_is_atleastone_loved_page\")\n",
    "    # filter on Page_Event_List becuase sometimes it doesn't match but Page_List is created from Page_Event_list so will always inlcude more\n",
    "    df['event_pages'] = df.Page_Event_List.apply(lambda x: [triple[0] for triple in x])\n",
    "    df['there_is_atleastone_loved_page'] = df.event_pages.map(lambda x: any([is_loved_page(page.split('?')[0]) for page in x]))\n",
    "    print(\"Derive var: is_loved_journey\")\n",
    "    df = df.assign(is_loved_journey = np.where(df.there_is_atleastone_loved_page==1, True, False))\n",
    "    \n",
    "    print(\"Number of occurences of journeys of this type\")\n",
    "    print(df[['Occurrences', 'is_loved_journey']].groupby('is_loved_journey').sum())\n",
    "    percent = df[['Occurrences', 'is_loved_journey']].groupby('is_loved_journey').sum().iloc[0]/(df[['Occurrences', \n",
    "                                                    'is_loved_journey']].groupby('is_loved_journey').sum().iloc[0] + \n",
    "                                                df[['Occurrences', 'is_loved_journey']].groupby('is_loved_journey').sum().iloc[1])\n",
    "    print(\"{:2.2%} of journeys are unloved on {}, a {}\".format(percent.item(), file_prefix, datetime.strptime(file_prefix, '%Y-%m-%d').strftime(\"%A\")))\n",
    "    print(\"writing files\")\n",
    "\n",
    "    df[df['is_loved_journey']==False].to_csv(os.path.join(DATA_DIR, f'processed_journey/unloved_{file_prefix}.csv.gz'), \n",
    "                                             sep=\"\\t\", \n",
    "                                             compression=\"gzip\", index=False)\n",
    "    df[df['is_loved_journey']==True].to_csv(\n",
    "        os.path.join(DATA_DIR, f'processed_journey/loved_{file_prefix}.csv.gz'), \n",
    "        sep=\"\\t\", \n",
    "        compression=\"gzip\", \n",
    "        index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_loved_and_unloved = sorted(glob.glob(\n",
    "        f'{DATA_DIR}/processed_journey/taxon_ab_*.csv.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/ellieking/Documents/govuk_ab_analysis/data/processed_journey/taxon_ab_2019-02-14.csv.gz',\n",
       " '/Users/ellieking/Documents/govuk_ab_analysis/data/processed_journey/taxon_ab_2019-02-15.csv.gz',\n",
       " '/Users/ellieking/Documents/govuk_ab_analysis/data/processed_journey/taxon_ab_2019-02-16.csv.gz',\n",
       " '/Users/ellieking/Documents/govuk_ab_analysis/data/processed_journey/taxon_ab_2019-02-17.csv.gz',\n",
       " '/Users/ellieking/Documents/govuk_ab_analysis/data/processed_journey/taxon_ab_2019-02-18.csv.gz',\n",
       " '/Users/ellieking/Documents/govuk_ab_analysis/data/processed_journey/taxon_ab_2019-02-19.csv.gz',\n",
       " '/Users/ellieking/Documents/govuk_ab_analysis/data/processed_journey/taxon_ab_2019-02-20.csv.gz',\n",
       " '/Users/ellieking/Documents/govuk_ab_analysis/data/processed_journey/taxon_ab_2019-02-21.csv.gz',\n",
       " '/Users/ellieking/Documents/govuk_ab_analysis/data/processed_journey/taxon_ab_2019-02-22.csv.gz',\n",
       " '/Users/ellieking/Documents/govuk_ab_analysis/data/processed_journey/taxon_ab_2019-02-23.csv.gz',\n",
       " '/Users/ellieking/Documents/govuk_ab_analysis/data/processed_journey/taxon_ab_2019-02-24.csv.gz',\n",
       " '/Users/ellieking/Documents/govuk_ab_analysis/data/processed_journey/taxon_ab_2019-02-25.csv.gz',\n",
       " '/Users/ellieking/Documents/govuk_ab_analysis/data/processed_journey/taxon_ab_2019-02-26.csv.gz']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_loved_and_unloved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50:50 in first day so exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading 2019-02-15 data\n",
      "page_list to literal list\n",
      "page_event_list to literal list\n",
      "Derive var: there_is_atleastone_loved_page\n",
      "Derive var: is_loved_journey\n",
      "Number of occurences of journeys of this type\n",
      "                  Occurrences\n",
      "is_loved_journey             \n",
      "False                  822428\n",
      "True                  2496762\n",
      "24.78% of journeys are unloved on 2019-02-15, a Friday\n",
      "writing files\n",
      "reading 2019-02-16 data\n",
      "page_list to literal list\n",
      "page_event_list to literal list\n",
      "Derive var: there_is_atleastone_loved_page\n",
      "Derive var: is_loved_journey\n",
      "Number of occurences of journeys of this type\n",
      "                  Occurrences\n",
      "is_loved_journey             \n",
      "False                  420231\n",
      "True                  1624571\n",
      "20.55% of journeys are unloved on 2019-02-16, a Saturday\n",
      "writing files\n",
      "reading 2019-02-17 data\n",
      "page_list to literal list\n",
      "page_event_list to literal list\n",
      "Derive var: there_is_atleastone_loved_page\n",
      "Derive var: is_loved_journey\n",
      "Number of occurences of journeys of this type\n",
      "                  Occurrences\n",
      "is_loved_journey             \n",
      "False                  424994\n",
      "True                  1647072\n",
      "20.51% of journeys are unloved on 2019-02-17, a Sunday\n",
      "writing files\n",
      "reading 2019-02-18 data\n",
      "page_list to literal list\n",
      "page_event_list to literal list\n",
      "Derive var: there_is_atleastone_loved_page\n",
      "Derive var: is_loved_journey\n",
      "Number of occurences of journeys of this type\n",
      "                  Occurrences\n",
      "is_loved_journey             \n",
      "False                 1022142\n",
      "True                  3110875\n",
      "24.73% of journeys are unloved on 2019-02-18, a Monday\n",
      "writing files\n",
      "reading 2019-02-19 data\n",
      "page_list to literal list\n",
      "page_event_list to literal list\n",
      "Derive var: there_is_atleastone_loved_page\n",
      "Derive var: is_loved_journey\n",
      "Number of occurences of journeys of this type\n",
      "                  Occurrences\n",
      "is_loved_journey             \n",
      "False                 1027237\n",
      "True                  2998973\n",
      "25.51% of journeys are unloved on 2019-02-19, a Tuesday\n",
      "writing files\n",
      "reading 2019-02-20 data\n",
      "page_list to literal list\n",
      "page_event_list to literal list\n",
      "Derive var: there_is_atleastone_loved_page\n",
      "Derive var: is_loved_journey\n",
      "Number of occurences of journeys of this type\n",
      "                  Occurrences\n",
      "is_loved_journey             \n",
      "False                 1003274\n",
      "True                  2995785\n",
      "25.09% of journeys are unloved on 2019-02-20, a Wednesday\n",
      "writing files\n",
      "reading 2019-02-21 data\n",
      "page_list to literal list\n",
      "page_event_list to literal list\n",
      "Derive var: there_is_atleastone_loved_page\n",
      "Derive var: is_loved_journey\n",
      "Number of occurences of journeys of this type\n",
      "                  Occurrences\n",
      "is_loved_journey             \n",
      "False                  943401\n",
      "True                  2844309\n",
      "24.91% of journeys are unloved on 2019-02-21, a Thursday\n",
      "writing files\n",
      "reading 2019-02-22 data\n",
      "page_list to literal list\n",
      "page_event_list to literal list\n",
      "Derive var: there_is_atleastone_loved_page\n",
      "Derive var: is_loved_journey\n",
      "Number of occurences of journeys of this type\n",
      "                  Occurrences\n",
      "is_loved_journey             \n",
      "False                  606240\n",
      "True                  1497446\n",
      "28.82% of journeys are unloved on 2019-02-22, a Friday\n",
      "writing files\n",
      "reading 2019-02-23 data\n",
      "page_list to literal list\n",
      "page_event_list to literal list\n",
      "Derive var: there_is_atleastone_loved_page\n",
      "Derive var: is_loved_journey\n",
      "Number of occurences of journeys of this type\n",
      "                  Occurrences\n",
      "is_loved_journey             \n",
      "False                   11997\n",
      "True                    28382\n",
      "29.71% of journeys are unloved on 2019-02-23, a Saturday\n",
      "writing files\n",
      "reading 2019-02-24 data\n",
      "page_list to literal list\n",
      "page_event_list to literal list\n",
      "Derive var: there_is_atleastone_loved_page\n",
      "Derive var: is_loved_journey\n",
      "Number of occurences of journeys of this type\n",
      "                  Occurrences\n",
      "is_loved_journey             \n",
      "False                    7186\n",
      "True                    15437\n",
      "31.76% of journeys are unloved on 2019-02-24, a Sunday\n",
      "writing files\n",
      "reading 2019-02-25 data\n",
      "page_list to literal list\n",
      "page_event_list to literal list\n",
      "Derive var: there_is_atleastone_loved_page\n",
      "Derive var: is_loved_journey\n",
      "Number of occurences of journeys of this type\n",
      "                  Occurrences\n",
      "is_loved_journey             \n",
      "False                    7122\n",
      "True                    12756\n",
      "35.83% of journeys are unloved on 2019-02-25, a Monday\n",
      "writing files\n",
      "reading 2019-02-26 data\n",
      "page_list to literal list\n",
      "page_event_list to literal list\n",
      "Derive var: there_is_atleastone_loved_page\n",
      "Derive var: is_loved_journey\n",
      "Number of occurences of journeys of this type\n",
      "                  Occurrences\n",
      "is_loved_journey             \n",
      "False                    4773\n",
      "True                     8942\n",
      "34.80% of journeys are unloved on 2019-02-26, a Tuesday\n",
      "writing files\n"
     ]
    }
   ],
   "source": [
    "for file in combined_loved_and_unloved[1:]:\n",
    "    date = re.search(r'\\d{4}-\\d{2}-\\d{2}', file)\n",
    "    split_daily_data(date.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
